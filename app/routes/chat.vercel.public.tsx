import type { Route } from "./+types/chat.vercel.public";
import { validateMonthlyConversationLimit } from "@/server/chatbot/planLimits.server";
import {
  streamText,
  convertToModelMessages,
  stepCountIs,
  type UIMessage,
} from "ai";
import { db } from "~/utils/db.server";
import {
  mapModel,
  getModelInfo,
} from "@/server/config/vercel.model.providers";
import { nanoid } from "nanoid";
import {
  createConversation,
  getConversationBySessionId,
} from "@/server/chatbot/conversationModel.server";
import {
  addAssistantMessage,
  addUserMessage,
  getMessagesByConversationId,
} from "@/server/chatbot/messageModel.server";
import { createGetContextTool } from "@/server/tools/vercel/vectorSearch";
import { createSaveLeadTool } from "@/server/tools/vercel/saveLead";
import { calculateCost } from "@/server/chatbot/pricing.server";

/**
 * ‚úÖ Loader para cargar mensajes hist√≥ricos (GET request)
 * El cliente usa esto para restaurar conversaciones al recargar
 */
export async function loader({ request }: Route.LoaderArgs) {
  const url = new URL(request.url);
  const sessionId = url.searchParams.get("sessionId");
  const chatbotId = url.searchParams.get("chatbotId");

  if (!sessionId || !chatbotId) {
    return Response.json({ messages: [] });
  }

  // Buscar conversaci√≥n por sessionId
  const conversation = await getConversationBySessionId(sessionId, chatbotId);

  if (!conversation) {
    return Response.json({ messages: [] });
  }

  // Cargar mensajes hist√≥ricos
  const dbMessages = await getMessagesByConversationId(conversation.id);
  const messages: UIMessage[] = dbMessages
    .filter((msg) => msg.role !== "SYSTEM")
    .map((msg) => ({
      id: msg.id,
      role: msg.role.toLowerCase() as "user" | "assistant",
      parts: [{ type: "text" as const, text: msg.content }],
    }));

  return Response.json({ messages });
}

export async function action({ request }: Route.ActionArgs) {
  const url = new URL(request.url);
  // ‚úÖ Patr√≥n "Last Message Only" - recibir solo el nuevo mensaje
  const { message, id: sessionId } = await request.json();
  const chatbotId = url.searchParams.get("chatbotId");

  // üîí VALIDAR FORMATO OBJECTID
  if (!chatbotId) {
    return Response.json(
      { error: "chatbotId inv√°lido o faltante" },
      { status: 404 }
    );
  }

  const chatbot = await db.chatbot.findUnique({
    where: { id: chatbotId, status: "ACTIVE" },
  });

  if (!chatbot) {
    return Response.json(
      { error: "Chatbot no encontrado o inactivo" },
      { status: 404 }
    );
  }

  // ‚úÖ BUSCAR conversaci√≥n existente ANTES de validar l√≠mites
  let conversation = await getConversationBySessionId(sessionId, chatbotId);

  // ‚úÖ CARGAR MENSAJES HIST√ìRICOS DE LA DB (patr√≥n 2025)
  let historicalMessages: UIMessage[] = [];
  if (conversation) {
    const dbMessages = await getMessagesByConversationId(conversation.id);
    historicalMessages = dbMessages
      .filter((msg) => msg.role !== "SYSTEM")
      .map((msg) => ({
        id: msg.id,
        role: msg.role.toLowerCase() as "user" | "assistant",
        parts: [{ type: "text" as const, text: msg.content }],
      }));
  }

  // Si la conversaci√≥n no existe, validar l√≠mites y crear nueva
  if (!conversation) {
    const limitCheck = await validateMonthlyConversationLimit(chatbotId);

    if (!limitCheck.canCreate) {
      return Response.json(
        {
          error: `Este chatbot ha alcanzado su l√≠mite mensual de conversaciones (${limitCheck.maxAllowed}). Por favor contacta al propietario.`,
        },
        { status: 429 }
      );
    }

    conversation = await createConversation({
      chatbotId,
      visitorId: nanoid(),
      visitorIp: request.headers.get("x-forwarded-for") || undefined,
      sessionId,
    });
  }

  // ‚úÖ COMBINAR mensajes hist√≥ricos + mensaje nuevo (patr√≥n "Last Message Only")
  const allMessages = [...historicalMessages, message];
  const textContent = message.parts
    .filter((p: any) => p.type === "text")
    .map((p: any) => p.text)
    .join("");

  await addUserMessage(conversation.id, textContent);

  const systemPrompt = `
    # Sigue estas instrucciones:
    ${chatbot.instructions}

    # Usa esta personalidad:
    ${chatbot.personality}

    # Considera, adem√°s, estas instrucciones:
    ${chatbot.customInstructions}

    # ‚ö†Ô∏è CR√çTICO - Uso de Knowledge Base:
    Tienes acceso a una base de conocimiento con informaci√≥n espec√≠fica sobre este negocio.
    - SIEMPRE usa la herramienta de b√∫squeda cuando el usuario haga preguntas espec√≠ficas
    - La informaci√≥n en la base de conocimiento es tu fuente de verdad
    - Si encuentras informaci√≥n relevante, √∫sala para responder
    - Si no encuentras informaci√≥n, indica claramente que no tienes esa informaci√≥n espec√≠fica
     `;

  // ‚è±Ô∏è Start time para medir responseTime
  const startTime = Date.now();

  // ‚úÖ PATR√ìN 2025: streamText con TODOS los mensajes (hist√≥ricos + nuevos)
  const result = streamText({
    model: mapModel(chatbot.aiModel),
    messages: convertToModelMessages(allMessages), // ‚¨ÖÔ∏è TODOS los mensajes
    system: systemPrompt,
    tools: {
      getContextTool: createGetContextTool(chatbotId),
      saveLeadTool: createSaveLeadTool(chatbotId),
    },
    stopWhen: stepCountIs(5),
    // üìä TRACKING: onFinish de streamText (recibe totalUsage)
    onFinish: async ({ text, totalUsage, finishReason }) => {
      try {
        // üìä TRACKING: Extraer m√©tricas de tokens
        const inputTokens = totalUsage?.promptTokens || 0;
        const outputTokens = totalUsage?.completionTokens || 0;
        const totalTokens = totalUsage?.totalTokens || inputTokens + outputTokens;

        // üîç Detectar provider y modelo
        const { provider, model } = getModelInfo(chatbot.aiModel);

        // üí∞ Calcular costo
        const costResult = calculateCost(provider, model, {
          inputTokens,
          outputTokens,
          cachedTokens: 0, // TODO: Vercel AI SDK no expone cached tokens a√∫n
        });

        // ‚è±Ô∏è Calcular tiempo de respuesta
        const responseTime = Date.now() - startTime;

        // üíæ Guardar mensaje con tracking completo
        await addAssistantMessage(
          conversation.id,
          text, // texto completo generado
          totalTokens, // tokens (legacy)
          responseTime, // responseTime en ms
          undefined, // firstTokenLatency (no disponible en Vercel AI SDK)
          model, // aiModel
          "web", // channel
          undefined, // externalMessageId
          inputTokens, // inputTokens
          outputTokens, // outputTokens
          costResult.totalCost, // totalCost en USD
          provider, // provider
          0 // cachedTokens
        );

        console.log(
          `[Chat Public] ‚úÖ Message tracked: ${totalTokens} tokens, $${costResult.totalCost.toFixed(6)} (${provider}/${model})`
        );
      } catch (error) {
        console.error("[Chat Public Action] ‚ùå Error saving message:", error);
      }
    },
  });

  // ‚úÖ PATR√ìN OFICIAL: toUIMessageStreamResponse CON originalMessages
  return result.toUIMessageStreamResponse({
    originalMessages: allMessages, // ‚¨ÖÔ∏è Env√≠a mensajes hist√≥ricos + nuevos al cliente
  });
}
