/**
 * Config Resolver para Chatbot
 * Centraliza la resoluci√≥n de configuraci√≥n separando business logic de agent logic
 */

import type { Chatbot, User } from "@prisma/client";
import { validateChatbotConfig, applyModelCorrection } from "./modelValidator.server";
import { PLAN_LIMITS } from "./planLimits.server";
import { getDefaultModelForPlan } from "~/utils/aiModels";

export interface ResolvedChatbotConfig {
  // Core config
  id: string;
  name: string;
  slug: string;

  // AI Configuration
  aiModel: string;
  temperature: number;
  maxTokens: number;

  // Prompts and personality
  instructions: string;
  customInstructions: string;
  personality: string;

  // UI Configuration
  primaryColor: string;
  avatarUrl: string;
  welcomeMessage: string;
  goodbyeMessage: string;

  // Context and training data
  contexts: any[];

  // Business logic metadata
  validationWarnings: string[];
  modelCorrected: boolean;
  originalModel?: string;
  planLimits: {
    maxTokensPerQuery: number;
    maxContextSizeKB: number;
    availableModels: string[];
  };
}

export interface AgentExecutionContext {
  userId: string;
  userPlan: string;
  chatbotId: string;
  message: string;
  integrations: Record<string, any>;
  sessionId?: string;
  conversationHistory?: Array<{ role: string; content: string }>;
}

/**
 * Resuelve la configuraci√≥n para usuarios AN√ìNIMOS (sin validaciones de plan)
 * Usa la configuraci√≥n del chatbot directamente sin restricciones
 *
 * üõ°Ô∏è IMPORTANTE: Aunque son an√≥nimos, SIEMPRE validar temperature para evitar alucinaciones
 */
export function resolveAnonymousChatbotConfig(chatbot: Chatbot): ResolvedChatbotConfig {
  const validationWarnings: string[] = [];

  // üõ°Ô∏è VALIDACI√ìN CR√çTICA: Temperature segura
  let safeTemperature = chatbot.temperature || 1;

  // NUNCA permitir temperature > 1.5 (causa alucinaciones multilenguaje)
  if (safeTemperature > 1.5) {
    console.warn(`‚ö†Ô∏è Temperature ${safeTemperature} DEMASIADO ALTA para chatbot ${chatbot.id}. Forzando a 1.0`);
    safeTemperature = 1.0;
    validationWarnings.push(`Temperature reducida de ${chatbot.temperature} a 1.0 por seguridad`);
  }

  // Para GPT-5 nano y gpt-4o-mini, forzar temperature=1 (√≥ptimo)
  const model = chatbot.aiModel;
  if (model === 'gpt-5-nano' || model === 'gpt-4o-mini') {
    if (safeTemperature !== 1) {
      console.log(`üîß Ajustando temperature a 1 para ${model} (requerido/√≥ptimo)`);
      safeTemperature = 1;
    }
  }

  // üõ°Ô∏è L√≠mite de tokens razonable (evitar loops infinitos)
  const safeMaxTokens = Math.min(chatbot.maxTokens || 800, 1000);

  return {
    // Core
    id: chatbot.id,
    name: chatbot.name,
    slug: chatbot.slug,

    // AI Config - CON validaciones de seguridad
    aiModel: chatbot.aiModel,
    temperature: safeTemperature,
    maxTokens: safeMaxTokens,

    // Prompts
    instructions: chatbot.instructions || "Eres un asistente virtual √∫til y profesional.",
    customInstructions: chatbot.customInstructions || "",
    personality: chatbot.personality || "customer_support",

    // UI
    primaryColor: chatbot.primaryColor || "#9A99EA",
    avatarUrl: chatbot.avatarUrl || "",
    welcomeMessage: chatbot.welcomeMessage || "¬°Hola! ¬øC√≥mo puedo ayudarte hoy?",
    goodbyeMessage: chatbot.goodbyeMessage || "¬°Gracias por usar nuestro servicio!",

    // Context - usar todos los contextos del chatbot
    contexts: (chatbot.contexts && Array.isArray(chatbot.contexts)) ? chatbot.contexts : [],

    // Metadata
    validationWarnings,
    modelCorrected: false,
    originalModel: chatbot.temperature !== safeTemperature ? `temp=${chatbot.temperature}` : undefined,
    planLimits: {
      maxTokensPerQuery: safeMaxTokens,
      maxContextSizeKB: 10000, // Sin l√≠mite efectivo para p√∫blicos
      availableModels: [chatbot.aiModel]
    }
  };
}

/**
 * Resuelve la configuraci√≥n completa del chatbot aplicando business rules
 */
export function resolveChatbotConfig(
  chatbot: Chatbot,
  user: User | { id: string; plan: string },
  context: Partial<AgentExecutionContext> = {}
): ResolvedChatbotConfig {
  // üë§ Usuarios an√≥nimos: usar configuraci√≥n simple sin validaciones
  if (user.plan === 'ANONYMOUS') {
    return resolveAnonymousChatbotConfig(chatbot);
  }

  const planLimits = PLAN_LIMITS[user.plan];

  // Si el plan no existe, usar configuraci√≥n an√≥nima
  if (!planLimits) {
    console.warn(`‚ö†Ô∏è Plan desconocido: ${user.plan}, usando configuraci√≥n an√≥nima`);
    return resolveAnonymousChatbotConfig(chatbot);
  }

  const validationWarnings: string[] = [];

  // 1. Resolver modelo AI con validaciones
  const modelCorrection = applyModelCorrection(user.plan, chatbot.aiModel, true);
  const finalModel = modelCorrection.finalModel;

  if (modelCorrection.wasCorreected) {
    validationWarnings.push(modelCorrection.warning || "Modelo corregido por restricciones del plan");
  }

  // 2. Resolver temperatura seg√∫n modelo
  let finalTemperature = chatbot.temperature || 0.7;

  // üõ°Ô∏è PROTECCI√ìN CR√çTICA: Temperature > 1.5 causa alucinaciones severas
  if (finalTemperature > 1.5) {
    console.warn(`‚ö†Ô∏è Temperature ${finalTemperature} DEMASIADO ALTA - caus√≥ alucinaciones multilenguaje. Reducida a 1.0`);
    validationWarnings.push(`‚ö†Ô∏è Temperature ${finalTemperature} es DEMASIADO ALTA (causa basura). Reducida a 1.0`);
    finalTemperature = 1.0;
  }

  // Para GPT-5 nano y gpt-4o-mini, FORZAR temperature=1 (√≥ptimo/requerido)
  if (finalModel === "gpt-5-nano" || finalModel === "gpt-4o-mini") {
    if (finalTemperature !== 1) {
      console.log(`üîß Ajustando temperature a 1 para ${finalModel} (√≥ptimo)`);
      validationWarnings.push(`Temperature ajustada a 1 para ${finalModel}`);
      finalTemperature = 1;
    }
  }

  // 3. Resolver l√≠mites de tokens
  const requestedMaxTokens = chatbot.maxTokens || planLimits.maxTokensPerQuery;
  const finalMaxTokens = Math.min(requestedMaxTokens, planLimits.maxTokensPerQuery);

  if (requestedMaxTokens > planLimits.maxTokensPerQuery) {
    validationWarnings.push(`Tokens limitados a ${planLimits.maxTokensPerQuery} por tu plan ${user.plan}`);
  }

  // 4. Resolver contextos aplicando l√≠mites de tama√±o
  // ‚ö° OPTIMIZACI√ìN: contextos no se cargan por defecto para mejorar performance
  let finalContexts: any[] = [];

  // Solo procesar contextos si est√°n disponibles (no lazy load por ahora)
  if (chatbot.contexts && Array.isArray(chatbot.contexts)) {
    finalContexts = chatbot.contexts;

    if (finalContexts.length > 0) {
      const totalContextSizeKB = finalContexts.reduce((acc, ctx) => acc + (ctx.sizeKB || 0), 0);

      if (totalContextSizeKB > planLimits.maxContextSizeKB) {
        // Truncar contextos si exceden el l√≠mite
        let currentSizeKB = 0;
        finalContexts = finalContexts.filter(ctx => {
          currentSizeKB += ctx.sizeKB || 0;
          return currentSizeKB <= planLimits.maxContextSizeKB;
        });

        validationWarnings.push(`Contextos truncados a ${planLimits.maxContextSizeKB}KB (l√≠mite del plan ${user.plan})`);
      }
    }
  }

  // 5. Resolver prompts con fallbacks seguros
  const finalInstructions = chatbot.instructions ||
    "Eres un asistente virtual √∫til y profesional. Responde de manera clara y concisa.";

  const finalCustomInstructions = chatbot.customInstructions || "";

  const finalPersonality = chatbot.personality || "customer_support";

  // 6. Resolver configuraci√≥n de UI con fallbacks
  const finalWelcomeMessage = chatbot.welcomeMessage ||
    "¬°Hola! ¬øC√≥mo puedo ayudarte hoy?";

  const finalGoodbyeMessage = chatbot.goodbyeMessage ||
    "¬°Gracias por usar nuestro servicio! Si necesitas m√°s ayuda, no dudes en escribir.";

  return {
    // Core
    id: chatbot.id,
    name: chatbot.name,
    slug: chatbot.slug,

    // AI Config
    aiModel: finalModel,
    temperature: finalTemperature,
    maxTokens: finalMaxTokens,

    // Prompts
    instructions: finalInstructions,
    customInstructions: finalCustomInstructions,
    personality: finalPersonality,

    // UI
    primaryColor: chatbot.primaryColor || "#9A99EA",
    avatarUrl: chatbot.avatarUrl || "",
    welcomeMessage: finalWelcomeMessage,
    goodbyeMessage: finalGoodbyeMessage,

    // Context
    contexts: finalContexts,

    // Metadata
    validationWarnings,
    modelCorrected: modelCorrection.wasCorreected,
    originalModel: modelCorrection.wasCorreected ? chatbot.aiModel : undefined,
    planLimits: {
      maxTokensPerQuery: planLimits.maxTokensPerQuery,
      maxContextSizeKB: planLimits.maxContextSizeKB,
      availableModels: planLimits.availableModels
    }
  };
}

/**
 * Crea el contexto de ejecuci√≥n para el agente
 */
export function createAgentExecutionContext(
  user: User | { id: string; plan: string },
  chatbotId: string,
  message: string,
  options: {
    sessionId?: string;
    conversationHistory?: Array<{ role: string; content: string }>;
    integrations?: Record<string, any>;
  } = {}
): AgentExecutionContext {
  return {
    userId: user.id,
    userPlan: user.plan,
    chatbotId,
    message,
    integrations: options.integrations || {},
    sessionId: options.sessionId,
    conversationHistory: options.conversationHistory || []
  };
}

/**
 * Valida que el usuario tenga acceso a las funcionalidades solicitadas
 */
export function validateUserAccess(
  user: User,
  requestedFeatures: {
    useTools?: boolean;
    useStreaming?: boolean;
    useAdvancedModels?: boolean;
  }
): {
  allowed: boolean;
  deniedFeatures: string[];
  reason?: string;
} {
  const planLimits = PLAN_LIMITS[user.plan];
  const deniedFeatures: string[] = [];

  // Usuarios FREE no tienen acceso a funcionalidades de chatbot
  if (user.plan === "FREE") {
    return {
      allowed: false,
      deniedFeatures: ["chatbots"],
      reason: "Plan gratuito no incluye acceso a chatbots"
    };
  }

  // Validar tools
  if (requestedFeatures.useTools && !["PRO", "ENTERPRISE", "TRIAL"].includes(user.plan)) {
    deniedFeatures.push("tools");
  }

  // Validar modelos avanzados
  if (requestedFeatures.useAdvancedModels) {
    const hasAdvancedModels = planLimits.availableModels.some(model =>
      model.includes("gpt-5") || model.includes("claude-3.5")
    );

    if (!hasAdvancedModels) {
      deniedFeatures.push("advanced_models");
    }
  }

  return {
    allowed: deniedFeatures.length === 0,
    deniedFeatures
  };
}

/**
 * Genera configuraci√≥n para logging y monitoring
 */
export function generateConfigMetadata(
  resolvedConfig: ResolvedChatbotConfig,
  context: AgentExecutionContext
): {
  logData: Record<string, any>;
  metricsData: Record<string, any>;
} {
  return {
    logData: {
      chatbotId: resolvedConfig.id,
      userId: context.userId,
      userPlan: context.userPlan,
      model: resolvedConfig.aiModel,
      modelCorrected: resolvedConfig.modelCorrected,
      originalModel: resolvedConfig.originalModel,
      temperature: resolvedConfig.temperature,
      maxTokens: resolvedConfig.maxTokens,
      contextsCount: resolvedConfig.contexts.length,
      warningsCount: resolvedConfig.validationWarnings.length,
      sessionId: context.sessionId
    },
    metricsData: {
      plan: context.userPlan,
      model: resolvedConfig.aiModel,
      has_contexts: resolvedConfig.contexts.length > 0,
      has_tools: ["PRO", "ENTERPRISE", "TRIAL"].includes(context.userPlan),
      config_corrected: resolvedConfig.validationWarnings.length > 0
    }
  };
}