import { db } from "~/utils/db.server";
import type { ParsingMode, ParsingStatus } from "@prisma/client";
import { LlamaParseReader } from "llama-cloud-services";
import { deleteParserFile } from "./upload.service";
import { validateAndDeduct } from "./credits.service";
import { countPDFPages, calculateCreditsForPages } from "./pdf-utils.server";

interface CreateParsingJobParams {
  chatbotId: string;
  userId: string;
  fileName: string;
  fileSize: number;
  fileType: string;
  mode: ParsingMode;
  options: any;
  fileBuffer: Buffer; // ‚≠ê Ahora necesitamos el buffer para contar p√°ginas
}

interface ParsingResult {
  markdown: string;
  pages: number;
  processingTime: number;
}

/**
 * Crear un nuevo job de parsing
 * Ahora calcula cr√©ditos basado en n√∫mero de p√°ginas del PDF
 */
export async function createParsingJob(params: CreateParsingJobParams) {
  // 1. Contar p√°ginas del PDF
  let pageCount = 10; // Fallback por defecto

  try {
    // Solo contar p√°ginas si es PDF
    if (params.fileType === "application/pdf" || params.fileName.toLowerCase().endsWith(".pdf")) {
      pageCount = await countPDFPages(params.fileBuffer);
    } else {
      // Para otros formatos (DOCX, XLSX, TXT), asumir 5 p√°ginas
      pageCount = 5;
    }
  } catch (error) {
    console.error("Error contando p√°ginas, usando fallback:", error);
    pageCount = 10; // Fallback conservador
  }

  // 2. Calcular cr√©ditos seg√∫n p√°ginas
  const credits = calculateCreditsForPages(params.mode, pageCount);


  // 3. Validar y descontar cr√©ditos ANTES de crear el job
  await validateAndDeduct(params.userId, credits);

  try {
    const job = await db.parsingJob.create({
      data: {
        chatbotId: params.chatbotId,
        userId: params.userId,
        fileName: params.fileName,
        fileSize: params.fileSize,
        fileType: params.fileType,
        mode: params.mode,
        options: params.options,
        status: "PENDING",
        creditsUsed: credits,
        pages: pageCount, // Guardar p√°ginas detectadas
      },
    });

    return job;
  } catch (error) {
    // Revertir cr√©ditos si falla la creaci√≥n del job
    console.error(`Error creando parsing job, revirtiendo ${credits} cr√©ditos para user ${params.userId}`);

    // Necesitamos revertir usando la l√≥gica dual (purchased + monthly)
    // Por simplicidad, aqu√≠ incrementamos solo purchased (deber√≠a ser m√°s sofisticado)
    await db.user.update({
      where: { id: params.userId },
      data: {
        purchasedCredits: { increment: credits },
        lifetimeCreditsUsed: { decrement: credits },
      },
    }).catch((revertError) => {
      console.error("Error revirtiendo cr√©ditos:", revertError);
    });

    throw error;
  }
}

/**
 * Obtener jobs del usuario (historial)
 */
export async function getUserParsingJobs(userId: string, limit = 10) {
  const jobs = await db.parsingJob.findMany({
    where: { userId },
    orderBy: { createdAt: "desc" },
    take: limit,
  });

  return jobs;
}

/**
 * Obtener un job por ID
 */
export async function getParsingJobById(jobId: string) {
  const job = await db.parsingJob.findUnique({
    where: { id: jobId },
  });

  return job;
}

/**
 * Mapear modo de Formmy a configuraci√≥n de LlamaParse
 */
function getParseConfig(mode: ParsingMode, options: any) {
  const baseConfig: any = {
    resultType: "markdown",
    verbose: false,
  };

  switch (mode) {
    case "COST_EFFECTIVE":
      return {
        ...baseConfig,
        // Modo simple y r√°pido
      };

    case "AGENTIC":
      return {
        ...baseConfig,
        // Modo balanceado con agent
        // @ts-ignore - LlamaParse types pueden no estar actualizados
        parseMode: "parse_page_with_agent",
        model: "openai-gpt-4-1-mini",
        adaptiveLongTable: options.extractTables,
        outlinedTableExtraction: options.extractTables,
        outputTablesAsHTML: options.preserveFormatting,
      };

    case "AGENTIC_PLUS":
      return {
        ...baseConfig,
        // Modo premium con alta precisi√≥n
        // @ts-ignore
        parseMode: "parse_page_with_agent",
        model: "openai-gpt-4-1-mini",
        highResOcr: options.extractImages,
        adaptiveLongTable: options.extractTables,
        outlinedTableExtraction: options.extractTables,
        outputTablesAsHTML: options.preserveFormatting,
      };

    default:
      return baseConfig;
  }
}

/**
 * ‚ö†Ô∏è NUNCA CAMBIAR ESTA BIBLIOTECA: unpdf es la opci√≥n correcta
 *
 * Razones:
 * - Dise√±ada espec√≠ficamente para serverless/edge/workers
 * - Mantenida activamente (2025)
 * - Optimizada para Agenda.js background jobs
 * - Recomendada por la comunidad sobre pdf-parse
 *
 * Si hay errores de serializaci√≥n, el problema es NUESTRO USO,
 * no la biblioteca. Asegurarse de retornar SOLO primitivos.
 */
async function basicParsing(fileUrl: string, fileName: string): Promise<ParsingResult> {
  const startTime = Date.now();

  try {

    // Descargar archivo
    const response = await fetch(fileUrl);
    if (!response.ok) {
      throw new Error(`Failed to download file: ${response.statusText}`);
    }

    const buffer = Buffer.from(await response.arrayBuffer());

    let markdown = "";
    let pages = 1;

    // Parsing b√°sico seg√∫n tipo de archivo
    if (fileName.toLowerCase().endsWith('.txt')) {
      markdown = buffer.toString('utf-8');
    } else if (fileName.toLowerCase().endsWith('.pdf')) {
      // ‚ö†Ô∏è unpdf: NO CAMBIAR - es la biblioteca correcta
      const { extractText } = await import('unpdf');

      // ‚úÖ CR√çTICO: unpdf requiere Uint8Array, NO Buffer
      const uint8Array = new Uint8Array(buffer);

      // Extraer texto de todas las p√°ginas
      const { text, totalPages } = await extractText(uint8Array, { mergePages: true });

      // ‚úÖ CR√çTICO: Solo primitivos serializables
      markdown = String(text || ''); // Forzar string
      pages = Number(totalPages || 1); // Forzar number
    } else {
      // Para otros formatos, intentar leer como texto
      markdown = buffer.toString('utf-8');
    }

    const processingTime = (Date.now() - startTime) / 1000;

    // ‚úÖ CR√çTICO: Garantizar que SOLO retornamos primitivos (string, number)
    // Esto evita errores de serializaci√≥n en Agenda.js workers
    return {
      markdown: String(markdown),
      pages: Number(pages),
      processingTime: Number(parseFloat(processingTime.toFixed(2))),
    };
  } catch (error) {
    console.error("‚ùå Basic parsing error:", error);
    throw new Error(
      `Error in basic parsing: ${error instanceof Error ? error.message : "Unknown error"}`
    );
  }
}

/**
 * Procesar documento con LlamaParse (modos avanzados)
 */
async function realParsing(
  fileUrl: string,
  fileName: string,
  mode: ParsingMode,
  options: any,
  llamaApiKey?: string // ‚≠ê Opcionalmente pasar la key
): Promise<ParsingResult> {
  const startTime = Date.now();

  try {
    // Usar key pasada como par√°metro o fallback a env var
    const llamaKey = llamaApiKey || process.env.LLAMA_CLOUD_API_KEY;

    if (!llamaKey) {
      throw new Error("API Key is required for LlamaParseReader. Please pass the apiKey parameter or set the LLAMA_CLOUD_API_KEY environment variable.");
    }

    // Inicializar LlamaParse reader
    const reader = new LlamaParseReader({
      apiKey: llamaKey,
      ...getParseConfig(mode, options),
    });


    // Procesar documento
    const documents = await reader.loadData(fileUrl);

    // Extraer markdown de los documentos
    let markdown = "";
    let totalPages = 0;

    if (Array.isArray(documents)) {
      markdown = documents.map((doc) => doc.text || "").join("\n\n");
      totalPages = documents.length;
    } else {
      markdown = documents.text || "";
      totalPages = 1;
    }

    const processingTime = (Date.now() - startTime) / 1000;


    return {
      markdown,
      pages: totalPages,
      processingTime,
    };
  } catch (error) {
    console.error("‚ùå LlamaParse error:", error);
    throw new Error(
      `Error parsing document: ${error instanceof Error ? error.message : "Unknown error"}`
    );
  }
}

/**
 * Procesar un job de parsing
 * Esta funci√≥n ser√° llamada por el worker/background processor
 */
export async function processParsingJob(
  jobId: string,
  fileUrl: string,
  fileKey: string,
  llamaApiKey?: string // ‚≠ê Par√°metro opcional para la API key
) {
  try {
    // 1. Actualizar estado a PROCESSING
    const job = await db.parsingJob.update({
      where: { id: jobId },
      data: { status: "PROCESSING" },
    });

    // 2. Procesar documento seg√∫n el modo
    const result = job.mode === "DEFAULT"
      ? await basicParsing(fileUrl, job.fileName) // DEFAULT = parsing b√°sico gratis
      : await realParsing(fileUrl, job.fileName, job.mode, job.options, llamaApiKey); // Otros = LlamaParse

    // 3. Eliminar archivo temporal de S3
    await deleteParserFile(fileKey);

    // 4. Actualizar con resultado exitoso
    const completedJob = await db.parsingJob.update({
      where: { id: jobId },
      data: {
        status: "COMPLETED",
        resultMarkdown: result.markdown,
        pages: result.pages,
        processingTime: result.processingTime,
        completedAt: new Date(),
      },
      select: {
        id: true,
        chatbotId: true,
        userId: true, // üîí Necesario para validaci√≥n de ownership
        fileName: true,
        fileType: true,
        fileSize: true,
        mode: true,
        creditsUsed: true,
      },
    });

    // 5. Agregar contexto usando WRAPPER SEGURO con Vercel AI SDK
    if (completedJob.chatbotId && result.markdown) {
      try {
        // üîí USAR WRAPPER SEGURO con validaci√≥n de ownership
        const { secureUpsert } = await import("server/context/vercel_embeddings.secure");

        const vectorResult = await secureUpsert({
          chatbotId: completedJob.chatbotId,
          title: completedJob.fileName,
          content: result.markdown,
          userId: completedJob.userId, // üîí Validaci√≥n de ownership
          metadata: {
            contextType: 'FILE',
            fileName: completedJob.fileName,
            fileType: completedJob.fileType,
            fileSize: completedJob.fileSize,
            contextId: jobId, // Preserve parser job ID
            // Metadata de parsing
            parsingMode: completedJob.mode,
            parsingPages: result.pages,
            parsingCredits: completedJob.creditsUsed,
          },
        });

        // ‚úÖ Success: Contexto creado exitosamente
        console.log(`‚úÖ Context created: ${vectorResult.contextId}, ${vectorResult.chunksCreated} chunks vectorized`);
      } catch (vectorError) {
        console.error(`‚ö†Ô∏è Vectorization failed after retries:`, vectorError);

        // Actualizar estado a COMPLETED_NO_VECTOR
        await db.parsingJob.update({
          where: { id: jobId },
          data: {
            status: "COMPLETED_NO_VECTOR",
            errorMessage: `Parsing successful but vectorization failed: ${
              vectorError instanceof Error ? vectorError.message : 'Unknown error'
            }`
          }
        });

        console.warn(`‚ö†Ô∏è Job ${jobId} marked as COMPLETED_NO_VECTOR - markdown available but not searchable`);
        return; // Exit early, don't throw
      }
    }

  } catch (error) {
    // 5. Manejar error
    console.error(`‚ùå Job ${jobId} failed:`, error);

    // Intentar limpiar archivo de S3 aunque haya fallado
    try {
      await deleteParserFile(fileKey);
    } catch (cleanupError) {
      console.error("Error cleaning up S3 file:", cleanupError);
    }

    await db.parsingJob.update({
      where: { id: jobId },
      data: {
        status: "FAILED",
        errorMessage:
          error instanceof Error ? error.message : "Error desconocido",
        completedAt: new Date(),
      },
    });
  }
}

/**
 * Actualizar estado del job manualmente
 */
export async function updateJobStatus(
  jobId: string,
  status: ParsingStatus,
  errorMessage?: string
) {
  await db.parsingJob.update({
    where: { id: jobId },
    data: {
      status,
      errorMessage,
      ...(status === "COMPLETED" || status === "FAILED"
        ? { completedAt: new Date() }
        : {}),
    },
  });
}
