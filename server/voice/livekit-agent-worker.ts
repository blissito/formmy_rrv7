/**
 * LiveKit Agent Worker
 * Worker que procesa conversaciones de voz usando LiveKit Inference Gateway
 */

import "dotenv/config";
import {
  type JobContext,
  type JobProcess,
  WorkerOptions,
  cli,
  defineAgent,
  voice,
} from '@livekit/agents';
import * as silero from '@livekit/agents-plugin-silero';
import * as elevenlabs from '@livekit/agents-plugin-elevenlabs';
import { fileURLToPath } from 'node:url';

if (!process.env.LIVEKIT_API_KEY || !process.env.LIVEKIT_API_SECRET) {
  console.error("âŒ Faltan LIVEKIT_API_KEY o LIVEKIT_API_SECRET");
  process.exit(1);
}

if (!process.env.OPENAI_API_KEY) {
  console.error("âŒ Falta OPENAI_API_KEY");
  process.exit(1);
}

if (!process.env.ELEVEN_API_KEY) {
  console.error("âŒ Falta ELEVEN_API_KEY (requerida para ElevenLabs plugin con voces custom)");
  process.exit(1);
}

console.log("ğŸš€ LiveKit Agent Worker starting...");
console.log(`ğŸ“¡ LiveKit URL: ${process.env.LIVEKIT_URL || 'wss://webrtcblissmo-ughbu8uu.livekit.cloud'}`);

export default defineAgent({
  // Prewarm: cargar modelos antes de procesar jobs
  prewarm: async (proc: JobProcess) => {
    console.log("ğŸ”¥ Prewarming: Cargando modelo Silero VAD...");
    proc.userData.vad = await silero.VAD.load();
    console.log("âœ… Silero VAD cargado");
  },

  entry: async (ctx: JobContext) => {
    console.log(`ğŸ™ï¸ Nuevo job de voz: Room ${ctx.room.name}`);

    // Obtener VAD del prewarm
    const vad = ctx.proc.userData.vad! as silero.VAD;

    // ğŸ” AUDITORÃA: Ver TODOS los lugares donde puede estar el metadata
    console.log(`\n${'ğŸ”'.repeat(40)}`);
    console.log(`ğŸ” [AUDITORÃA] Buscando metadata en TODOS los lugares posibles:`);
    console.log(`   1. ctx.room.metadata: ${ctx.room.metadata}`);
    console.log(`   2. ctx.job disponible: ${!!ctx.job}`);

    // Intentar leer desde el job primero (donde SÃ viene en los logs)
    let roomMetadataString = ctx.room.metadata;

    if (!roomMetadataString && (ctx as any).job?.room?.metadata) {
      console.log(`   âœ… Metadata encontrado en ctx.job.room.metadata`);
      roomMetadataString = (ctx as any).job.room.metadata;
    }

    console.log(`   3. Metadata string final a parsear: ${roomMetadataString?.substring(0, 100)}...`);

    const metadata = roomMetadataString ? JSON.parse(roomMetadataString) : {};

    console.log(`\n   Metadata PARSEADO:`, JSON.stringify(metadata, null, 2));
    console.log(`${'ğŸ”'.repeat(40)}\n`);

    const {
      instructions = "Eres un asistente de voz Ãºtil y profesional.",
      customInstructions = "",
      voiceWelcome = "Hola, Â¿en quÃ© puedo ayudarte hoy?",
      ttsVoiceId = "3l9iCMrNSRR0w51JvFB0", // Leo Moreno - ÃšNICA voz nativa mexicana en nuestra cuenta ElevenLabs
    } = metadata;

    console.log(`ğŸ“Œ Valores extraÃ­dos del metadata:`);
    console.log(`   instructions: "${instructions}"`);
    console.log(`   customInstructions: "${customInstructions}"`);
    console.log(`   customInstructions.length: ${customInstructions.length}`);

    // ğŸ¯ CONSTRUIR PROMPT CON PRIORIDAD A CUSTOM INSTRUCTIONS
    let systemPrompt = "";

    if (customInstructions && customInstructions.trim()) {
      // Si hay customInstructions, son PRIORIDAD MÃXIMA
      systemPrompt = `ğŸ¯ TU PERSONALIZACIÃ“N (PRIORIDAD MÃXIMA):

${customInstructions}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

IMPORTANTE PARA VOZ:
- Respuestas ULTRA CORTAS (1-2 oraciones mÃ¡ximo)
- Conversacional y natural
- Sin listas largas ni explicaciones extensas`;
    } else {
      // Fallback a instrucciones genÃ©ricas
      systemPrompt = `${instructions}

IMPORTANTE PARA VOZ:
- Respuestas ULTRA CORTAS (1-2 oraciones mÃ¡ximo)
- Conversacional y natural
- Sin listas largas ni explicaciones extensas`;
    }

    console.log(`\n${'ğŸ“‹'.repeat(40)}`);
    console.log(`ğŸ“‹ [VOICE WORKER] System prompt construido:`);
    console.log(`   customInstructions presente: ${!!customInstructions && !!customInstructions.trim()}`);
    if (customInstructions) {
      console.log(`   customInstructions: "${customInstructions}"`);
    }
    console.log(`\n   SYSTEM PROMPT COMPLETO:\n${systemPrompt}`);
    console.log(`${'ğŸ“‹'.repeat(40)}\n`);
    console.log(`ğŸ¤ Voice ID configurada: ${ttsVoiceId}`);

    // Crear el agente
    const assistant = new voice.Agent({
      instructions: systemPrompt,
    });

    // âš ï¸ CRÃTICO: Usar ElevenLabs Plugin con configuraciÃ³n CORRECTA
    // Esto permite usar voces nativas en espaÃ±ol (Leo Moreno)
    const tts = new elevenlabs.TTS({
      voice: { id: ttsVoiceId }, // âœ… Formato correcto segÃºn docs LiveKit
      model: "eleven_turbo_v2_5", // Modelo rÃ¡pido y de alta calidad
      language: "es", // âœ… EspaÃ±ol (cÃ³digo ISO-639-1)
      streaming_latency: 1, // âœ… Baja latencia (1 segundo, default es 3)
    });

    // Crear la sesiÃ³n de voz con ElevenLabs Plugin + VAD
    // USANDO DEEPGRAM STT + ELEVENLABS PLUGIN TTS con voz nativa mexicana
    const session = new voice.AgentSession({
      vad, // âœ… Voice Activity Detection
      stt: "deepgram/nova-2-general:es", // âœ… Deepgram Nova-2 - ESPAÃ‘OL (idioma ISO-639-1)
      llm: "openai/gpt-4o-mini",
      tts, // âœ… ElevenLabs Plugin con voz custom (Leo Moreno)
    });

    console.log(`ğŸ™ï¸ ConfiguraciÃ³n: VAD=Silero, STT=deepgram/nova-2:es, LLM=gpt-4o-mini, TTS=ElevenLabs Plugin (${ttsVoiceId})`);

    // Conectarse al room
    await ctx.connect();
    console.log(`âœ… Conectado a room: ${ctx.room.name}`);

    // Iniciar sesiÃ³n con mejores opciones de input
    await session.start({
      agent: assistant,
      room: ctx.room,
    });

    console.log("âœ… SesiÃ³n de voz iniciada con VAD y turn-detection");

    // âš ï¸ IMPORTANTE: Esperar a que el participante (usuario) se conecte antes de enviar saludo
    console.log("â³ Esperando a que el usuario se conecte...");

    // Esperar a que haya al menos 1 participante remoto (el usuario)
    const waitForParticipant = new Promise<void>((resolve) => {
      const checkParticipants = () => {
        const remoteParticipants = Array.from(ctx.room.remoteParticipants.values());
        if (remoteParticipants.length > 0) {
          console.log(`âœ… Usuario conectado: ${remoteParticipants[0].identity}`);
          resolve();
        } else {
          setTimeout(checkParticipants, 100); // Revisar cada 100ms
        }
      };
      checkParticipants();
    });

    await waitForParticipant;

    // âš ï¸ CRÃTICO: Esperar mÃ¡s tiempo para que el cliente estÃ© completamente listo
    // El cliente necesita tiempo para:
    // 1. Conectarse al room
    // 2. Configurar event listeners
    // 3. Estar listo para suscribirse a tracks del agente
    console.log("â³ Esperando 2 segundos para que cliente estÃ© listo...");
    await new Promise(r => setTimeout(r, 2000)); // Aumentado de 500ms a 2s

    // Ahora sÃ­, enviar mensaje de bienvenida usando say() para TTS directo
    console.log(`ğŸ’¬ Enviando mensaje de bienvenida: "${voiceWelcome}"`);
    console.log(`ğŸ¤ Con voz: ${ttsVoiceId} (Leo Moreno - Voz nativa mexicana)`);

    try {
      await session.say(voiceWelcome, {
        allowInterruptions: true, // âœ… Permitir que el usuario interrumpa
      });
      console.log("âœ… Mensaje de bienvenida enviado exitosamente");
    } catch (error) {
      console.error("âŒ Error al enviar mensaje de bienvenida:", error);
    }

    // Auto-disconnect a los 10 minutos
    setTimeout(async () => {
      console.log("â±ï¸ LÃ­mite de 10 minutos alcanzado");
      await session.say("Hemos llegado al lÃ­mite de tiempo. Fue un placer ayudarte. Â¡Hasta luego!");
      await new Promise(r => setTimeout(r, 5000));
      await ctx.disconnect();
    }, 10 * 60 * 1000);

    console.log("âœ… Agente de voz activo y escuchando con turn-taking...");
  },
});

// âš ï¸ CRÃTICO: Pasar el path del archivo al WorkerOptions
cli.runApp(new WorkerOptions({ agent: fileURLToPath(import.meta.url) }));
