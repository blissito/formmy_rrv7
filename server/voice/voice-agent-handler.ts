/**
 * Voice Agent Handler
 * Maneja conversaciones de voz en tiempo real integrando LiveKit con agentes de Formmy
 */

import { Room, RoomEvent, Track, type RemoteParticipant, type RemoteTrack } from "livekit-server-sdk";
import { db } from "server/db/db.server";
import {
  incrementMessageCount,
  updateTranscription,
  failVoiceSession,
} from "./livekit-voice.service";
import { streamAgentWorkflow } from "server/agents/agent-workflow.server";
import { getChatbotById } from "server/chatbot/chatbot.service.server";
import { getUserById } from "server/user/user.service.server";

/**
 * Evento de transcripci√≥n del STT (Speech-to-Text)
 */
interface TranscriptionEvent {
  text: string;
  isFinal: boolean; // Si es transcripci√≥n final o parcial
  timestamp: number;
}

/**
 * Handler principal para una sesi√≥n de voz
 * Se ejecuta cuando un usuario se conecta a un room de LiveKit
 */
export class VoiceAgentHandler {
  private sessionId: string;
  private room: Room | null = null;
  private transcriptionBuffer: string[] = [];
  private conversationHistory: Array<{ role: "user" | "assistant"; content: string }> = [];
  private isProcessing = false;

  constructor(sessionId: string) {
    this.sessionId = sessionId;
  }

  /**
   * Inicializa el handler y se conecta al room
   */
  async start() {
    const session = await db.voiceSession.findUnique({
      where: { id: this.sessionId },
      include: {
        chatbot: {
          include: {
            user: true,
          },
        },
      },
    });

    if (!session) {
      throw new Error(`Voice session not found: ${this.sessionId}`);
    }

    console.log(`üéôÔ∏è Starting voice agent for session: ${this.sessionId}`);

    // Conectar al room de LiveKit como agente
    // NOTA: En producci√≥n, este handler correr√≠a como un servidor separado
    // que escucha eventos de LiveKit v√≠a webhooks o conexi√≥n directa

    // Por ahora, este es el esqueleto de la l√≥gica
    // La implementaci√≥n completa requerir√≠a:
    // 1. LiveKit Agent SDK (livekit-agents)
    // 2. Plugins de STT (AssemblyAI, Deepgram)
    // 3. Plugins de TTS (Cartesia, ElevenLabs)

    console.log(`‚úÖ Voice agent ready for room: ${session.roomName}`);
  }

  /**
   * Procesa un evento de transcripci√≥n del usuario
   */
  async handleTranscription(event: TranscriptionEvent) {
    // Solo procesar transcripciones finales
    if (!event.isFinal) {
      return;
    }

    const userMessage = event.text.trim();
    if (!userMessage) {
      return;
    }

    // ‚úÖ Si el usuario interrumpe mientras procesamos, registrar interrupci√≥n
    // pero NO ignorar el mensaje (las interrupciones son naturales en voz)
    if (this.isProcessing) {
      console.log(`‚ö†Ô∏è User interrupted while processing. Queuing new message: "${userMessage}"`);
      // En una implementaci√≥n completa, aqu√≠ podr√≠amos cancelar el procesamiento actual
      // Por ahora, simplemente dejamos que termine y procesamos el nuevo mensaje despu√©s
      return;
    }

    console.log(`üë§ User said: ${userMessage}`);
    this.isProcessing = true;

    try {
      // Agregar a historial
      this.conversationHistory.push({
        role: "user",
        content: userMessage,
      });

      // Obtener datos de sesi√≥n
      const session = await db.voiceSession.findUnique({
        where: { id: this.sessionId },
        include: {
          chatbot: {
            include: {
              user: true,
              integrations: true,
            },
          },
        },
      });

      if (!session) {
        throw new Error("Session not found");
      }

      // Construir user object
      const user = {
        id: session.userId,
        plan: session.chatbot.user.plan,
      };

      // Construir integrations object
      const integrations = session.chatbot.integrations.reduce((acc: any, integration: any) => {
        acc[integration.platform] = {
          isActive: integration.isActive,
          ...integration,
        };
        return acc;
      }, {});

      // Construir resolvedConfig
      const resolvedConfig = {
        name: session.chatbot.name,
        personality: session.chatbot.personality || "friendly",
        instructions: session.chatbot.instructions,
        customInstructions: session.chatbot.customInstructions,
        aiModel: session.chatbot.aiModel,
        temperature: session.chatbot.temperature,
      };

      // Construir agentContext con historial conversacional
      const agentContext = {
        conversationId: session.conversationId,
        isGhosty: false,
        conversationHistory: this.conversationHistory, // ‚úÖ Pasar historial completo aqu√≠
        integrations,
      };

      console.log(`\n${'üéôÔ∏è'.repeat(40)}`);
      console.log(`üéôÔ∏è [VoiceHandler] Llamando a streamAgentWorkflow`);
      console.log(`   user.id: ${user.id}`);
      console.log(`   user.plan: ${user.plan}`);
      console.log(`   chatbotId: ${session.chatbotId}`);
      console.log(`   message: "${userMessage}"`);
      console.log(`   chatbot.name: "${session.chatbot.name}"`);
      console.log(`   customInstructions: "${resolvedConfig.customInstructions?.substring(0, 100)}..."`);
      console.log(`   conversationHistory: ${this.conversationHistory.length} mensajes`);
      console.log(`   isGhosty: ${agentContext.isGhosty}`);
      console.log(`${'üéôÔ∏è'.repeat(40)}\n`);

      // Llamar al agente de Formmy con streaming (firma correcta)
      let agentResponse = "";

      for await (const chunk of streamAgentWorkflow(
        user,
        userMessage,
        session.chatbotId,
        {
          resolvedConfig,
          agentContext,
        }
      )) {
        if (chunk.type === "text") {
          agentResponse += chunk.content;
        } else if (chunk.type === "tool_call") {
          console.log(`üîß Tool called: ${chunk.tool}`);
        }
      }

      console.log(`ü§ñ Agent response: ${agentResponse}`);

      // Agregar respuesta al historial
      this.conversationHistory.push({
        role: "assistant",
        content: agentResponse,
      });

      // Incrementar contador de mensajes
      await incrementMessageCount(this.sessionId);

      // Actualizar transcripci√≥n
      const fullTranscription = this.conversationHistory
        .map((msg) => `${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}`)
        .join("\n\n");
      await updateTranscription(this.sessionId, fullTranscription);

      // Convertir respuesta a TTS y enviar de vuelta al usuario
      await this.sendVoiceResponse(agentResponse, session.ttsProvider, session.ttsVoiceId);

    } catch (error) {
      console.error(`‚ùå Error processing transcription: ${error}`);
      await failVoiceSession(this.sessionId, String(error));
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * Convierte texto a voz y lo env√≠a al usuario
   */
  private async sendVoiceResponse(
    text: string,
    ttsProvider: string,
    ttsVoiceId: string | null
  ) {
    // NOTA: Esta es una implementaci√≥n simplificada
    // En producci√≥n, usar√≠amos LiveKit Inference API o plugins de TTS

    console.log(`üîä Sending voice response (${ttsProvider}): ${text.substring(0, 50)}...`);

    // TODO: Implementar TTS con LiveKit Inference API
    // const ttsUrl = `https://api.livekit.io/inference/tts`;
    // const audioBuffer = await fetch(ttsUrl, {
    //   method: "POST",
    //   headers: {
    //     "Authorization": `Bearer ${LIVEKIT_API_KEY}`,
    //     "Content-Type": "application/json",
    //   },
    //   body: JSON.stringify({
    //     text,
    //     provider: ttsProvider, // "cartesia" | "elevenlabs" | "inworld"
    //     voice: ttsVoiceId,
    //     language: "es-MX",
    //   }),
    // });

    // En producci√≥n, el audio se enviar√≠a al room de LiveKit
    // y se reproducir√≠a autom√°ticamente en el cliente
  }

  /**
   * Limpia recursos cuando la sesi√≥n termina
   */
  async cleanup() {
    console.log(`üßπ Cleaning up voice agent for session: ${this.sessionId}`);

    if (this.room) {
      // Desconectar del room
      this.room = null;
    }

    // Guardar transcripci√≥n final
    const fullTranscription = this.conversationHistory
      .map((msg) => `${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}`)
      .join("\n\n");

    if (fullTranscription) {
      await updateTranscription(this.sessionId, fullTranscription);
    }
  }
}

/**
 * Crea y arranca un handler para una sesi√≥n de voz
 */
export async function startVoiceAgentHandler(sessionId: string): Promise<VoiceAgentHandler> {
  const handler = new VoiceAgentHandler(sessionId);
  await handler.start();
  return handler;
}

/**
 * Simula el procesamiento de una transcripci√≥n (para testing)
 */
export async function processVoiceTranscription(
  sessionId: string,
  transcription: string
): Promise<string> {
  const handler = new VoiceAgentHandler(sessionId);

  // Procesar transcripci√≥n
  await handler.handleTranscription({
    text: transcription,
    isFinal: true,
    timestamp: Date.now(),
  });

  // Retornar el √∫ltimo mensaje del asistente
  const session = await db.voiceSession.findUnique({
    where: { id: sessionId },
  });

  return session?.transcription || "";
}
