# Prompt Engineering Best Practices - Formmy

Este documento describe las tÃ©cnicas de prompt engineering usadas en Ghosty y otros agentes de Formmy, comparadas con las mejores prÃ¡cticas oficiales de Anthropic y LlamaIndex.

## ðŸ“– Fuentes oficiales

- **Anthropic Prompt Engineering**: https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview
- **Chain of Thought**: https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought
- **LlamaIndex Agent Workflows**: https://developers.llamaindex.ai/typescript/framework/modules/agents/agent_workflow/

## ðŸŽ¯ Principios fundamentales

### 1. Clarity and Directness (Anthropic)

**Malo:**
```
Intenta usar la herramienta de bÃºsqueda cuando sea necesario.
```

**Bueno:**
```
â›” PROHIBICIONES ABSOLUTAS:
1. NUNCA respondas preguntas sobre el negocio sin buscar PRIMERO
2. NUNCA digas "no sÃ©" sin AGOTAR todas las herramientas de bÃºsqueda
```

### 2. Chain of Thought (Anthropic)

**Malo:**
```
Responde la pregunta del usuario.
```

**Bueno:**
```
ðŸ¤” Razonamiento interno (NO compartir con usuario):
   1. Pregunta sobre caracterÃ­sticas nuevas del negocio
   2. Debo buscar PRIMERO en base de conocimiento
   3. Si no encuentro â†’ buscar en web AUTOMÃTICAMENTE
   4. NO puedo decir "no sÃ©" sin intentar ambas
   5. NO debo preguntar al usuario - DEBO HACERLO

âœ… AcciÃ³n correcta (ejecuciÃ³n silenciosa):
   â†’ search_context("caracterÃ­sticas nuevas...")
   â†’ [Sin resultados]
   â†’ web_search_google("Formmy caracterÃ­sticas 2025")
   â†’ Respuesta directa
```

### 3. Few-shot Examples (Anthropic)

**Malo:**
```
Usa mÃºltiples bÃºsquedas para preguntas complejas.
```

**Bueno:**
```
EJEMPLO 1: "Â¿QuÃ© caracterÃ­sticas nuevas tiene Formmy?"

âœ… AcciÃ³n correcta:
   â†’ search_context("caracterÃ­sticas nuevas")
   â†’ search_context("novedades funcionalidades")
   â†’ web_search_google("Formmy actualizaciones 2025")
   â†’ Responder

âŒ Respuesta INCORRECTA:
   "No tengo informaciÃ³n..."
   "Â¿Te gustarÃ­a que busque?"
```

## ðŸ”¥ TÃ©cnicas avanzadas (Beyond Anthropic)

### 1. Ejemplos de respuestas PROHIBIDAS con frases exactas

En lugar de solo decir "no hagas X", mostramos **exactamente las frases que el modelo estaba usando**:

```typescript
âŒ Respuesta INCORRECTA:
   "Parece que he tenido dificultades... Â¿Te gustarÃ­a que busque?"
   "Vamos a hacer una bÃºsqueda mÃ¡s optimizada"
```

**Por quÃ© funciona**: El modelo reconoce sus propios patrones de output y aprende a evitarlos.

### 2. Protocolo de cascada con advertencias explÃ­citas

```typescript
PASO 2 - Fallback a Web (AUTOMÃTICO si PASO 1 falla):
âš ï¸ NO PREGUNTES al usuario si quiere que busques - HAZLO DIRECTAMENTE
â†’ Si search_context NO tiene resultados despuÃ©s de 2+ intentos
â†’ EJECUTAR web_search_google INMEDIATAMENTE
â†’ Query debe incluir: "${businessDomain} [tema] 2025"
```

**Por quÃ© funciona**: Advertencias inline previenen comportamientos no deseados en cada paso.

### 3. Razonamiento interno vs. externo

```typescript
ðŸ¤” Razonamiento interno (NO compartir con usuario):
   1. Analizar pregunta...
   2. Decidir estrategia...
   3. Ejecutar herramientas...

âœ… AcciÃ³n correcta (ejecuciÃ³n silenciosa):
   â†’ tool_call_1
   â†’ tool_call_2
   â†’ Respuesta directa al usuario
```

**Por quÃ© funciona**: El agente "piensa" (mejora accuracy) pero no "habla en voz alta" (mejor UX).

### 4. Templates concretas para queries

En lugar de "be specific", damos templates:

```typescript
â†’ Query debe incluir: "${businessDomain} [tema] 2025"
```

**Ejemplos generados**:
- "Formmy caracterÃ­sticas nuevas 2025"
- "Formmy precios planes 2025"

## ðŸ› ï¸ Patterns de LlamaIndex (100% oficial)

Todo nuestro cÃ³digo usa los patterns oficiales de LlamaIndex:

```typescript
// âœ… PATRÃ“N OFICIAL
const agentConfig = {
  llm,                    // LLM instance
  tools: allTools,        // Array de tools
  systemPrompt,           // â† Nuestros prompts mejorados
  verbose: true,
  memory                  // Memoria conversacional
};

return agent(agentConfig);
```

Para tools:

```typescript
// âœ… PATRÃ“N OFICIAL
tool(
  async (params) => { /* handler */ },
  {
    name: "search_context",
    description: `...`,  // â† Descripciones detalladas
    parameters: z.object({ /* zod schema */ })
  }
)
```

**NO hacemos ninguna lÃ³gica custom**. Solo usamos los parÃ¡metros oficiales del API con prompts mejor escritos.

## ðŸ“Š Resultados validados

Script de prueba: `scripts/test-rag-prompts.ts`

```bash
DEVELOPMENT_TOKEN=FORMMY_DEV_TOKEN_2025 npx tsx scripts/test-rag-prompts.ts
```

**Ãšltimos resultados (Oct 4, 2025)**:

| Test | search_context | web_search | CrÃ©ditos | Status |
|------|----------------|------------|----------|--------|
| CaracterÃ­sticas nuevas | 2x | 1x | 7 | âœ… |
| Planes y formas de pago | 4x | 2x | 14 | âœ… |
| Comparar Starter vs Pro | 4x | 4x | 20 | âœ… |

**Comportamiento validado**:
- âœ… Descompone preguntas complejas en sub-consultas
- âœ… Hace 2-4 bÃºsquedas `search_context` con queries reformuladas
- âœ… Fallback automÃ¡tico a `web_search_google`
- âœ… Exhaustivo (hasta 8 herramientas ejecutadas!)
- âœ… No usa frases prohibidas

## ðŸŽ“ Lecciones aprendidas

### 1. Los modelos imitan patrones, no solo siguen reglas

**Regla abstracta**: "Usa mÃºltiples bÃºsquedas"
**PatrÃ³n concreto**: Mostrar ejemplo completo con razonamiento â†’ âœ… Funciona mejor

### 2. Prohibiciones explÃ­citas > Sugerencias implÃ­citas

**Malo**: "Cuando no sepas algo, intenta buscar"
**Bueno**: "NUNCA digas 'no sÃ©' sin AGOTAR todas las herramientas"

### 3. Ejemplos de fracaso son tan importantes como de Ã©xito

Mostrar **quÃ© NO hacer** con las frases exactas que el modelo usa ayuda a corregir comportamiento.

### 4. El prompt ES el comportamiento

La diferencia entre Claude Code y Ghosty NO es el modelo - es el prompt.
Mismo modelo (GPT-4o-mini), comportamiento radicalmente diferente.

## ðŸ“š Referencias

### Ejemplos profesionales encontrados con gh CLI:

**LlamaIndex oficial** (blog-writer.ts):
```
You are a research agent. Your role is to gather information
from the internet using the provided tools and then transfer
this information to the report agent for content creation.
```
â†’ Simple, directo, define rol y workflow

**Azure AI Travel Agents**:
```
Assists employees in better understanding customer needs,
facilitating more accurate and personalized service.
```
â†’ Define propÃ³sito y valor del agente

**Nuestro approach** (Ghosty):
```
â›” PROHIBICIONES ABSOLUTAS:
1. NUNCA respondas sin buscar PRIMERO
2. NUNCA digas "no sÃ©" sin AGOTAR herramientas

âœ… PROTOCOLO OBLIGATORIO:
PASO 1 - Base de conocimiento (search_context)
PASO 2 - Fallback a web (web_search_google)
PASO 3 - Ãšltimo recurso: decir "busquÃ© pero no encontrÃ©"

ðŸ“Š EJEMPLOS CON RAZONAMIENTO:
...
```
â†’ Mucho mÃ¡s detallado, pero **necesario para comportamiento agÃ©ntico complejo**

## ðŸŽ¯ ConclusiÃ³n

Nuestros prompts son **mÃ¡s verbosos** que los ejemplos bÃ¡sicos de LlamaIndex/Azure, pero estÃ¡n **alineados con las mejores prÃ¡cticas de Anthropic** para casos de uso complejos:

- âœ… Clarity and directness (imperativos)
- âœ… Chain of thought (razonamiento paso a paso)
- âœ… Few-shot examples (con reasoning)
- âœ… Structural techniques (secciones con emojis)
- âœ… Tool usage prompts (descripciones detalladas)

**Y vamos mÃ¡s allÃ¡**:
- Ejemplos de respuestas incorrectas con frases exactas
- Protocolo de cascada con advertencias inline
- Razonamiento interno vs. externo
- Templates concretas para queries

El resultado: **Ghosty ahora tiene comportamiento agÃ©ntico comparable a Claude Code**.
